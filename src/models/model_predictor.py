# src/models/model_predictor.py
import pandas as pd
import numpy as np
import xgboost as xgb
import json
import os
from typing import Dict, Tuple, Optional, Any

from data.data_collector import DataCollector
from data.feature_engineer import FeatureEngineer
from utils.config_loader import ConfigLoader
from utils.logger import get_logger, debug_logger, performance_logger

# ä½¿ç”¨é¡¹ç›®ç»Ÿä¸€çš„æ—¥å¿—å·¥å…·
logger = get_logger(__name__)

class ModelPredictor:
    """
    Aè‚¡æ¨¡å‹é¢„æµ‹å™¨
    è´Ÿè´£åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
    """
    
    def __init__(self, config_path="config"):
        config_loader = ConfigLoader(config_path)
        self.config = config_loader.load_all_configs()
        self.data_collector = DataCollector()
        self.feature_engineer = FeatureEngineer(self.config['features'])
        self.model_registry = {}
        self._is_ready = False
        
        logger.info("æ¨¡å‹é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ", extra={
            'trading_context': {
                'action': 'predictor_initialized',
                'config_path': config_path
            }
        })

    def initialize(self, symbols: list = None) -> bool:
        """åˆå§‹åŒ–æ¨¡å‹é¢„æµ‹å™¨"""
        try:
            # å°è¯•åŠ è½½æ¨¡å‹
            self._is_ready = self.load_models(symbols)
            return self._is_ready
        except Exception as e:
            logger.error(f"æ¨¡å‹é¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def load_models(self, symbols: list) -> bool:
        """
        æ‰¹é‡åŠ è½½å¤šä¸ªæ¨¡å‹
        æ ¹æ®ä¼ å…¥çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨åŠ è½½å¯¹åº”çš„æ¨¡å‹
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['000001', '000002', '600036']
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½è‡³å°‘ä¸€ä¸ªæ¨¡å‹
        """
        logger.info("å¼€å§‹æ‰¹é‡åŠ è½½æ¨¡å‹", extra={
            'trading_context': {
                'action': 'batch_model_loading_start',
                'symbol_count': len(symbols)
            }
        })
        
        try:
            if not symbols:
                logger.error("æœªæä¾›è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œæ— æ³•åŠ è½½æ¨¡å‹", extra={
                    'trading_context': {
                        'error': 'no_symbols_provided'
                    }
                })
                return False
            
            logger.info("å‡†å¤‡åŠ è½½æ¨¡å‹åˆ—è¡¨", extra={
                'trading_context': {
                    'action': 'models_identified',
                    'model_count': len(symbols),
                    'symbols': symbols
                }
            })
            
            # æ‰¹é‡åŠ è½½æ¨¡å‹
            success_count = 0
            failed_models = []
            
            for symbol in symbols:
                if self.load_model(symbol):
                    success_count += 1
                else:
                    failed_models.append(symbol)
            
            # è®°å½•åŠ è½½ç»“æœ
            logger.info("æ‰¹é‡åŠ è½½æ¨¡å‹å®Œæˆ", extra={
                'trading_context': {
                    'action': 'batch_model_loading_complete',
                    'total_models': len(symbols),
                    'success_count': success_count,
                    'failed_count': len(failed_models),
                    'success_rate': success_count / len(symbols) if symbols else 0
                }
            })
            
            if failed_models:
                logger.warning("éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥", extra={
                    'trading_context': {
                        'warning': 'partial_model_loading_failure',
                        'failed_models_count': len(failed_models),
                        'failed_models': failed_models
                    }
                })
            
            # å¦‚æœè‡³å°‘æˆåŠŸåŠ è½½äº†ä¸€ä¸ªæ¨¡å‹ï¼Œå°±è®¤ä¸ºæ˜¯å°±ç»ªçŠ¶æ€
            is_ready = success_count > 0
            
            if is_ready:
                logger.info("æ¨¡å‹é¢„æµ‹å™¨å°±ç»ª", extra={
                    'trading_context': {
                        'action': 'predictor_ready',
                        'loaded_models_count': success_count,
                        'ready_status': is_ready
                    }
                })
            else:
                logger.error("æ¨¡å‹é¢„æµ‹å™¨æœªå°±ç»ªï¼šæ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹", extra={
                    'trading_context': {
                        'error': 'predictor_not_ready',
                        'reason': 'no_models_loaded_successfully'
                    }
                })
            
            return is_ready
            
        except Exception as e:
            logger.error("æ‰¹é‡åŠ è½½æ¨¡å‹å¤±è´¥", extra={
                'trading_context': {
                    'error': 'batch_model_loading_failed',
                    'error_message': str(e)
                }
            })
            return False
        
    def load_model(self, symbol: str) -> bool:
        """
        åŠ è½½æŒ‡å®šè‚¡ç¥¨çš„æ¨¡å‹
        """
        logger.info("å¼€å§‹åŠ è½½æ¨¡å‹", extra={
            'trading_context': {
                'symbol': symbol,
                'action': 'model_loading_start'
            }
        })
        
        try:
            model_path = f"models/xgboost/{symbol}/model.json"
            metadata_path = f"models/xgboost/{symbol}/metadata.json"
            
            if not os.path.exists(model_path):
                logger.error("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨", extra={
                    'trading_context': {
                        'symbol': symbol,
                        'error': 'model_file_not_found',
                        'model_path': model_path
                    }
                })
                return False
            
            # åŠ è½½æ¨¡å‹
            model = xgb.XGBClassifier()
            model.load_model(model_path)
            
            # åŠ è½½å…ƒæ•°æ®
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            self.model_registry[symbol] = {
                'model': model,
                'metadata': metadata,
                'feature_columns': metadata.get('feature_columns', [])
            }
            
            accuracy = metadata.get('accuracy', 'æœªçŸ¥')
            feature_count = len(metadata.get('feature_columns', []))
            
            logger.info("æˆåŠŸåŠ è½½æ¨¡å‹", extra={
                'trading_context': {
                    'symbol': symbol,
                    'action': 'model_loaded_success',
                    'accuracy': accuracy,
                    'feature_count': feature_count,
                    'training_date': metadata.get('training_date', 'æœªçŸ¥')
                }
            })
            
            return True
            
        except Exception as e:
            logger.error("åŠ è½½æ¨¡å‹å¤±è´¥", extra={
                'trading_context': {
                    'symbol': symbol,
                    'error': 'model_loading_failed',
                    'error_message': str(e)
                }
            })
            return False
        
    def is_ready(self) -> bool:
            """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å°±ç»ª"""
            return self._is_ready
    """
    Aè‚¡æ¨¡å‹é¢„æµ‹å™¨ - æ·»åŠ predictæ–¹æ³•ä»¥å…¼å®¹DecisionMaker
    """
    
    # ç°æœ‰çš„åˆå§‹åŒ–ä»£ç ä¿æŒä¸å˜...
    
    def predict(self, symbol: str, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        predictæ–¹æ³• - ä¾›DecisionMakerè°ƒç”¨
        æ¥å£å…¼å®¹Agentæ¶æ„
        """
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if not self._is_ready:
            raise Exception("æ¨¡å‹æœªå°±ç»ªï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
        
        try:
            # ä½¿ç”¨ç°æœ‰çš„predict_single_stockæ–¹æ³•
            prediction_result = self.predict_single_stock(symbol)
            
            if prediction_result is None:
                return self._get_default_prediction(symbol)
            
            # è½¬æ¢ä¸ºDecisionMakeréœ€è¦çš„æ ¼å¼
            return self._format_prediction_for_decision_maker(prediction_result, market_data)
            
        except Exception as e:
            logger.error(f"é¢„æµ‹å¤±è´¥ {symbol}: {e}")
            return self._get_default_prediction(symbol)
    
    def _format_prediction_for_decision_maker(self, prediction_result: Dict[str, Any], 
                                            market_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–é¢„æµ‹ç»“æœä¾›DecisionMakerä½¿ç”¨"""
        # ç¡®å®šæ–¹å‘
        if prediction_result['prediction_type'] == "bullish":
            direction = "buy"
        else:
            direction = "sell"
        
        # è·å–å½“å‰ä»·æ ¼
        current_price = market_data.get('current_price', 0)
        if current_price == 0:
            current_price = prediction_result.get('current_price', 0)
        
        # è®¡ç®—é¢„æœŸä»·æ ¼ï¼ˆåŸºäºç½®ä¿¡åº¦å’Œæ–¹å‘ï¼‰
        confidence = prediction_result['confidence']
        if direction == "buy":
            expected_change = 0.02 * confidence  # åŸºäºç½®ä¿¡åº¦çš„é¢„æœŸæ¶¨å¹…
        else:
            expected_change = -0.02 * confidence  # åŸºäºç½®ä¿¡åº¦çš„é¢„æœŸè·Œå¹…
        
        expected_price = current_price * (1 + expected_change)
        
        return {
            "symbol": prediction_result['symbol'],
            "direction": direction,
            "confidence": confidence,
            "prediction_proba": [
                prediction_result['down_probability'],
                prediction_result['up_probability']
            ],
            "expected_price": expected_price,
            "expected_change": expected_change,
            "timestamp": prediction_result['prediction_time'],
            "model_accuracy": prediction_result['model_accuracy'],
            "raw_prediction": prediction_result  # ä¿ç•™åŸå§‹é¢„æµ‹ä¿¡æ¯
        }
    
    def _get_default_prediction(self, symbol: str) -> Dict[str, Any]:
        """è·å–é»˜è®¤é¢„æµ‹ç»“æœ"""
        return {
            "symbol": symbol,
            "direction": "hold",
            "confidence": 0.0,
            "prediction_proba": [0.5, 0.5],
            "expected_price": 0,
            "expected_change": 0,
            "timestamp": pd.Timestamp.now().isoformat(),
            "model_accuracy": 0.5,
            "reason": "é¢„æµ‹å¤±è´¥"
        }
    
    # ç°æœ‰çš„å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜...
    
    def predict_single_stock(self, symbol: str) -> Optional[Dict]:
        """
        é¢„æµ‹å•åªè‚¡ç¥¨ - å¢åŠ æ•°æ®è·å–é•¿åº¦
        """
        logger.info("å¼€å§‹é¢„æµ‹è‚¡ç¥¨", extra={
            'trading_context': {
                'symbol': symbol,
                'action': 'prediction_start'
            }
        })
        
        start_time = pd.Timestamp.now()
        
        try:
            # 1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
            if symbol not in self.model_registry:
                if not self.load_model(symbol):
                    return None
            
            model_info = self.model_registry[symbol]
            # 2. è·å–æ›´é•¿çš„å†å²æ•°æ®ä»¥æ”¯æŒå­£åº¦ç‰¹å¾è®¡ç®—
            # quarter_lag_20 å¯èƒ½éœ€è¦ 20*60 â‰ˆ 1200 ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
            debug_logger.log_data_processing(symbol, "data_fetch", {
                "days": 1200,  # å¢åŠ åˆ°1200å¤©
                "action": "prediction_data_extended"
            })
            
            recent_data = self.data_collector.download_recent_data(symbol, days=1200)
            if recent_data is None:
                logger.error("è·å–é¢„æµ‹æ•°æ®å¤±è´¥", extra={
                    'trading_context': {
                        'symbol': symbol,
                        'error': 'prediction_data_fetch_failed'
                    }
                })
                return None
            
            # 3. ç‰¹å¾å·¥ç¨‹
            debug_logger.log_data_processing(symbol, "feature_engineering", {
                "data_points": len(recent_data),
                "action": "prediction_features"
            })
            
            featured_data = self.feature_engineer.create_features(
                recent_data, target_type="close_close", for_prediction=True
            )
            
            # å…¶ä½™ä»£ç ä¿æŒä¸å˜...
            
            if featured_data is None:
                logger.error("ç‰¹å¾å·¥ç¨‹å¤±è´¥", extra={
                    'trading_context': {
                        'symbol': symbol,
                        'error': 'feature_engineering_failed'
                    }
                })
                return None
            
            # 4. å‡†å¤‡é¢„æµ‹ç‰¹å¾
            prediction_features = self._prepare_prediction_features(
                featured_data, model_info['feature_columns'], symbol
            )
            
            if prediction_features is None:
                return None
            
            # 5. è¿›è¡Œé¢„æµ‹
            prediction_result = self._make_prediction(
                model_info['model'], prediction_features, symbol
            )

            if prediction_result:
                duration = (pd.Timestamp.now() - start_time).total_seconds()
                
                # ä¿®å¤ï¼šä¼ é€’å­—å…¸å‚æ•°è€Œä¸æ˜¯å¤šä¸ªä½ç½®å‚æ•°
                performance_logger.log_prediction({
                    'symbol': symbol,
                    'prediction': prediction_result['prediction'],
                    'confidence': prediction_result['confidence'],
                    'up_probability': prediction_result['up_probability'],
                    'duration_seconds': duration,
                    'model_accuracy': prediction_result['model_accuracy']
                })
                
                logger.info("è‚¡ç¥¨é¢„æµ‹å®Œæˆ", extra={
                    'trading_context': {
                        'symbol': symbol,
                        'action': 'prediction_complete',
                        'prediction': prediction_result['prediction'],
                        'confidence': prediction_result['confidence'],
                        'duration_seconds': duration
                    }
                })

            return prediction_result
            
        except Exception as e:
            logger.error("é¢„æµ‹è‚¡ç¥¨å¤±è´¥", extra={
                'trading_context': {
                    'symbol': symbol,
                    'error': 'prediction_failed',
                    'error_message': str(e),
                    'duration_seconds': (pd.Timestamp.now() - start_time).total_seconds()
                }
            })
            return None
    
    def predict_multiple_stocks(self, symbols: list) -> Dict:
        """
        æ‰¹é‡é¢„æµ‹å¤šåªè‚¡ç¥¨
        """
        logger.info("å¼€å§‹æ‰¹é‡é¢„æµ‹", extra={
            'trading_context': {
                'action': 'batch_prediction_start',
                'symbol_count': len(symbols),
                'symbols': symbols
            }
        })
        
        start_time = pd.Timestamp.now()
        predictions = {}
        
        for symbol in symbols:
            prediction = self.predict_single_stock(symbol)
            predictions[symbol] = prediction
        
        # ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
        report = self._generate_prediction_report(predictions)
        
        duration = (pd.Timestamp.now() - start_time).total_seconds()
        logger.info("æ‰¹é‡é¢„æµ‹å®Œæˆ", extra={
            'trading_context': {
                'action': 'batch_prediction_complete',
                'total_stocks': len(symbols),
                'successful_predictions': report['successful_predictions'],
                'failed_predictions': report['failed_predictions'],
                'average_confidence': report['average_confidence'],
                'duration_seconds': duration
            }
        })
        
        return report
    
    def _prepare_prediction_features(self, data, feature_columns, symbol):
        """
        å‡†å¤‡é¢„æµ‹ç‰¹å¾ - å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—
        """
        try:
            # ä½¿ç”¨æœ€æ–°çš„æ•°æ®ç‚¹
            latest_data = data.iloc[-1:]
            
            logger.debug("åŸå§‹æ•°æ®ç‰¹å¾", extra={
                'trading_context': {
                    'symbol': symbol,
                    'available_features_sample': list(data.columns)[:10],
                    'data_shape': data.shape
                }
            })

            # æ£€æŸ¥æ¨¡å‹å…ƒæ•°æ®ï¼Œçœ‹æ˜¯å¦æœ‰ç‰¹å¾é‡è¦æ€§ä¿¡æ¯
            model_info = self.model_registry[symbol]
            metadata = model_info.get('metadata', {})
            feature_importance = metadata.get('feature_importance', {})
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«æ‰€éœ€ç‰¹å¾
            missing_features = []
            feature_data = {}
            
            for feature in feature_columns:
                if feature in latest_data.columns:
                    feature_value = latest_data[feature].values[0]
                    if pd.isna(feature_value) or np.isinf(feature_value):
                        # å¯¹äºé‡è¦ç‰¹å¾ï¼Œå°è¯•ä½¿ç”¨æ›¿ä»£å€¼
                        if feature_importance.get(feature, 0) > 0.01:  # é‡è¦æ€§é˜ˆå€¼
                            logger.warning("é‡è¦ç‰¹å¾å€¼æ— æ•ˆï¼Œä½¿ç”¨å›é€€å€¼", extra={
                                'trading_context': {
                                    'symbol': symbol,
                                    'warning': 'important_feature_invalid',
                                    'feature': feature,
                                    'importance': feature_importance.get(feature, 0)
                                }
                            })
                        feature_data[feature] = 0
                    else:
                        feature_data[feature] = feature_value
                else:
                    feature_data[feature] = 0
                    missing_features.append(feature)
                    
                    # è®°å½•ç‰¹å¾é‡è¦æ€§
                    importance = feature_importance.get(feature, 0)
                    if importance > 0.05:  # é«˜é‡è¦æ€§ç‰¹å¾ç¼ºå¤±
                        logger.error("é«˜é‡è¦æ€§ç‰¹å¾ç¼ºå¤±", extra={
                            'trading_context': {
                                'symbol': symbol,
                                'error': 'high_importance_feature_missing',
                                'feature': feature,
                                'importance': importance
                            }
                        })
            
            # ä¸€æ¬¡æ€§åˆ›å»ºDataFrame
            matched_features = pd.DataFrame([feature_data], index=latest_data.index)
            
            if missing_features:
                logger.warning("å‘ç°ç¼ºå¤±ç‰¹å¾", extra={
                    'trading_context': {
                        'symbol': symbol,
                        'warning': 'missing_features',
                        'missing_count': len(missing_features),
                        'missing_features': missing_features,
                        'required_features_sample': feature_columns[:5]
                    }
                })
                
                # è®°å½•è¯¦ç»†çš„ç‰¹å¾å¯¹æ¯”
                available_features = set(data.columns)
                required_features = set(feature_columns)
                logger.debug("ç‰¹å¾å¯¹æ¯”è¯¦æƒ…", extra={
                    'trading_context': {
                        'symbol': symbol,
                        'available_features_count': len(available_features),
                        'required_features_count': len(required_features),
                        'intersection_count': len(available_features & required_features)
                    }
                })
            
            debug_logger.log_data_processing(symbol, "prediction_features", {
                "feature_count": len(feature_columns),
                "missing_features": len(missing_features),
                "data_shape": matched_features.shape,
                "available_data_points": len(data)
            })
            
            return matched_features
            
        except Exception as e:
            logger.error("å‡†å¤‡é¢„æµ‹ç‰¹å¾å¤±è´¥", extra={
                'trading_context': {
                    'symbol': symbol,
                    'error': 'prediction_features_preparation_failed',
                    'error_message': str(e),
                    'feature_columns_sample': feature_columns[:5] if feature_columns else []
                }
            })
            return None
    
    def _make_prediction(self, model, features, symbol):
        """
        è¿›è¡Œæ¨¡å‹é¢„æµ‹ - æ›´æ–°é¢„æµ‹æè¿°
        """
        try:
            debug_logger.log_model_training(symbol, {
                "action": "making_prediction",
                "feature_shape": features.shape
            })
            
            # é¢„æµ‹æ¦‚ç‡
            prediction_proba = model.predict_proba(features)[0]
            up_probability = prediction_proba[1]
            down_probability = prediction_proba[0]
            
            # ç¡®å®šé¢„æµ‹æ–¹å‘ - æ›´æ–°æè¿°
            if up_probability > down_probability:
                prediction = "ğŸ“ˆ æ˜æ—¥ä¸Šæ¶¨"  # ä¿®æ”¹æè¿°
                confidence = up_probability
                prediction_type = "bullish"
            else:
                prediction = "ğŸ“‰ æ˜æ—¥ä¸‹è·Œ"  # ä¿®æ”¹æè¿°
                confidence = down_probability
                prediction_type = "bearish"
            
            # è·å–å½“å‰ä»·æ ¼ä¿¡æ¯
            current_data = self.data_collector.get_current_price(symbol)
            
            result = {
                'symbol': symbol,
                'name': current_data.get('name', '') if current_data else '',
                'prediction': prediction,
                'prediction_type': prediction_type,
                'up_probability': float(up_probability),
                'down_probability': float(down_probability),
                'confidence': float(confidence),
                'current_price': current_data.get('current', 0) if current_data else 0,
                'current_open': current_data.get('open', 0) if current_data else 0,
                'prediction_time': pd.Timestamp.now().isoformat(),
                'model_accuracy': self.model_registry[symbol]['metadata'].get('accuracy', 0),
                'prediction_description': 'æ˜æ—¥æ”¶ç›˜ç›¸å¯¹ä»Šæ—¥æ”¶ç›˜çš„æ¶¨è·Œ'  # æ·»åŠ æè¿°
            }
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            self._save_prediction_result(result)
            
            debug_logger.log_model_training(symbol, {
                "action": "prediction_complete",
                "prediction": prediction,
                "confidence": confidence,
                "up_probability": up_probability,
                "down_probability": down_probability
            })
            
            return result
            
        except Exception as e:
            logger.error("æ¨¡å‹é¢„æµ‹å¤±è´¥", extra={
                'trading_context': {
                    'symbol': symbol,
                    'error': 'model_prediction_failed',
                    'error_message': str(e)
                }
            })
            return None
    
    def _save_prediction_result(self, prediction_result):
        """
        ä¿å­˜é¢„æµ‹ç»“æœ
        """
        try:
            symbol = prediction_result['symbol']
            predictions_dir = f"results/predictions/{symbol}"
            os.makedirs(predictions_dir, exist_ok=True)
            
            # æŒ‰æ—¥æœŸä¿å­˜
            date_str = pd.Timestamp.now().strftime("%Y%m%d")
            file_path = f"{predictions_dir}/prediction_{date_str}.json"
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(prediction_result, f, indent=2, ensure_ascii=False)
                
            debug_logger.log_data_processing(symbol, "prediction_saved", {
                "file_path": file_path,
                "prediction": prediction_result['prediction']
            })
            
        except Exception as e:
            logger.error("ä¿å­˜é¢„æµ‹ç»“æœå¤±è´¥", extra={
                'trading_context': {
                    'error': 'prediction_save_failed',
                    'symbol': prediction_result.get('symbol', 'unknown'),
                    'error_message': str(e)
                }
            })
    
    def _generate_prediction_report(self, predictions):
        """
        ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
        """
        try:
            successful_predictions = {k: v for k, v in predictions.items() if v is not None}
            failed_predictions = {k: v for k, v in predictions.items() if v is None}
            
            if successful_predictions:
                confidences = [p['confidence'] for p in successful_predictions.values()]
                average_confidence = np.mean(confidences)
                bullish_count = sum(1 for p in successful_predictions.values() 
                                   if p['prediction_type'] == "bullish")
                bearish_count = sum(1 for p in successful_predictions.values() 
                                   if p['prediction_type'] == "bearish")
            else:
                average_confidence = 0
                bullish_count = 0
                bearish_count = 0
            
            report = {
                'total_stocks': len(predictions),
                'successful_predictions': len(successful_predictions),
                'failed_predictions': len(failed_predictions),
                'average_confidence': float(average_confidence),
                'bullish_count': bullish_count,
                'bearish_count': bearish_count,
                'bullish_ratio': bullish_count / len(successful_predictions) if successful_predictions else 0,
                'prediction_date': pd.Timestamp.now().isoformat(),
                'details': successful_predictions,
                'prediction_target': 'æ˜æ—¥æ”¶ç›˜ç›¸å¯¹ä»Šæ—¥æ”¶ç›˜çš„æ¶¨è·Œ'  # æ·»åŠ é¢„æµ‹ç›®æ ‡è¯´æ˜
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_dir = "results"
            os.makedirs(report_dir, exist_ok=True)
            report_path = f"{report_dir}/prediction_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            performance_logger.log_performance({
                'batch_prediction_stats': {
                    'total_stocks': report['total_stocks'],
                    'success_rate': report['successful_predictions'] / report['total_stocks'],
                    'average_confidence': report['average_confidence'],
                    'bullish_ratio': report['bullish_ratio']
                }
            })
            
            logger.info("é¢„æµ‹æŠ¥å‘Šå·²ä¿å­˜", extra={
                'trading_context': {
                    'action': 'prediction_report_saved',
                    'report_path': report_path,
                    'successful_predictions': report['successful_predictions'],
                    'failed_predictions': report['failed_predictions'],
                    'average_confidence': report['average_confidence'],
                    'bullish_count': report['bullish_count']
                }
            })
            
            return report
            
        except Exception as e:
            logger.error("ç”Ÿæˆé¢„æµ‹æŠ¥å‘Šå¤±è´¥", extra={
                'trading_context': {
                    'error': 'prediction_report_generation_failed',
                    'error_message': str(e)
                }
            })
            return {}
    
    def get_prediction_summary(self) -> Dict:
        """
        è·å–é¢„æµ‹å™¨çŠ¶æ€æ‘˜è¦
        """
        loaded_models = list(self.model_registry.keys())
        
        summary = {
            'loaded_models_count': len(loaded_models),
            'loaded_models': loaded_models,
            'model_details': {}
        }
        
        for symbol, model_info in self.model_registry.items():
            metadata = model_info['metadata']
            summary['model_details'][symbol] = {
                'accuracy': metadata.get('accuracy'),
                'feature_count': len(model_info['feature_columns']),
                'training_date': metadata.get('training_date'),
                'model_type': metadata.get('model_type'),
                'target_description': metadata.get('target', 'æœªçŸ¥')  # æ·»åŠ ç›®æ ‡æè¿°
            }
        
        logger.debug("è·å–é¢„æµ‹å™¨çŠ¶æ€æ‘˜è¦", extra={
            'trading_context': {
                'action': 'predictor_summary',
                'loaded_models_count': len(loaded_models)
            }
        })
        
        return summary
    
    def clear_model_cache(self, symbol: str = None) -> bool:
        """
        æ¸…é™¤æ¨¡å‹ç¼“å­˜
        """
        try:
            if symbol:
                if symbol in self.model_registry:
                    del self.model_registry[symbol]
                    logger.info("æ¸…é™¤å•ä¸ªæ¨¡å‹ç¼“å­˜", extra={
                        'trading_context': {
                            'action': 'model_cache_cleared',
                            'symbol': symbol
                        }
                    })
                    return True
                else:
                    logger.warning("æ¨¡å‹æœªåœ¨ç¼“å­˜ä¸­", extra={
                        'trading_context': {
                            'warning': 'model_not_in_cache',
                            'symbol': symbol
                        }
                    })
                    return False
            else:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                cleared_count = len(self.model_registry)
                self.model_registry.clear()
                logger.info("æ¸…é™¤æ‰€æœ‰æ¨¡å‹ç¼“å­˜", extra={
                    'trading_context': {
                        'action': 'all_models_cache_cleared',
                        'cleared_count': cleared_count
                    }
                })
                return True
                
        except Exception as e:
            logger.error("æ¸…é™¤æ¨¡å‹ç¼“å­˜å¤±è´¥", extra={
                'trading_context': {
                    'error': 'model_cache_clear_failed',
                    'symbol': symbol or 'all',
                    'error_message': str(e)
                }
            })
            return False